# 1. Preprocessing and Dataset Loading

import os
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_auc_score

# Paths
train_dir = "path/to/dataset/train"
test_dir = "path/to/dataset/test"
output_csv = "submission.csv"

# Image size and batch size
img_size = (128, 128)
batch_size = 32

# Load training data
train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="training",
)
val_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="validation",
)
