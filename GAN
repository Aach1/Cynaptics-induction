'''
2. Building a GAN for Feature Learning
A GAN consists of:
Generator: Generates synthetic images to mimic real ones.
Discriminator: Classifies images as real or fake (learns features).
'''

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, UpSampling2D, LeakyReLU
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt

# GAN Parameters
img_shape = (128, 128, 3)
latent_dim = 100

# Generator
def build_generator():
    model = Sequential([
        Dense(256 * 16 * 16, activation="relu", input_dim=latent_dim),
        Reshape((16, 16, 256)),
        UpSampling2D(),
        Conv2D(128, (3, 3), padding="same"),
        LeakyReLU(alpha=0.2),
        UpSampling2D(),
        Conv2D(64, (3, 3), padding="same"),
        LeakyReLU(alpha=0.2),
        Conv2D(3, (3, 3), activation="tanh", padding="same"),
    ])
    return model

# Discriminator
def build_discriminator():
    model = Sequential([
        Conv2D(64, (3, 3), strides=(2, 2), input_shape=img_shape, padding="same"),
        LeakyReLU(alpha=0.2),
        Conv2D(128, (3, 3), strides=(2, 2), padding="same"),
        LeakyReLU(alpha=0.2),
        Flatten(),
        Dense(1, activation="sigmoid"),
    ])
    return model

# Compile the GAN
def build_gan(generator, discriminator):
    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss="binary_crossentropy", metrics=["accuracy"])
    discriminator.trainable = False  # Freeze discriminator during GAN training
    z = Input(shape=(latent_dim,))
    img = generator(z)
    validity = discriminator(img)
    gan = Model(z, validity)
    gan.compile(optimizer=Adam(0.0002, 0.5), loss="binary_crossentropy")
    return gan

# Initialize models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

# Train the GAN
def train_gan(generator, discriminator, gan, epochs=10000, batch_size=32, sample_interval=1000):
    # Load real images
    real_images = np.array([img for img, _ in train_data]) * 2 - 1  # Normalize to [-1, 1]

    for epoch in range(epochs):
        # Train discriminator
        idx = np.random.randint(0, real_images.shape[0], batch_size)
        real_imgs = real_images[idx]
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        fake_imgs = generator.predict(noise)

        d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((batch_size, 1)))
        d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        valid_y = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(noise, valid_y)

        # Output progress
        if epoch % sample_interval == 0:
            print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]")

# Train the GAN
train_gan(generator, discriminator, gan)
