# This was used in Gradient competition on kaggle

# 1. Preprocessing and Dataset Loading

import os
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_auc_score

# Paths
train_dir = "path/to/dataset/train"
test_dir = "path/to/dataset/test"
output_csv = "submission.csv"

# Image size and batch size
img_size = (128, 128)
batch_size = 32

# Load training data
train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="training",
)
val_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="validation",
)

# 2. Train a CNN Classifier

# Build the CNN model
cnn_model = Sequential([
    Conv2D(32, (3, 3), activation="relu", input_shape=(128, 128, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation="relu"),
    Dropout(0.5),
    Dense(1, activation="sigmoid"),  # Binary classification
])

cnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Train the CNN model
early_stop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
cnn_model.fit(train_data, validation_data=val_data, epochs=20, callbacks=[early_stop])

# Save the trained model
cnn_model.save("cnn_real_vs_ai.h5")


# 3. Train a GAN and Use the Discriminator

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, UpSampling2D, LeakyReLU
from tensorflow.keras.optimizers import Adam

# GAN Parameters
latent_dim = 100

# Build Generator
def build_generator():
    model = Sequential([
        Dense(256 * 16 * 16, activation="relu", input_dim=latent_dim),
        Reshape((16, 16, 256)),
        UpSampling2D(),
        Conv2D(128, (3, 3), padding="same"),
        LeakyReLU(alpha=0.2),
        UpSampling2D(),
        Conv2D(64, (3, 3), padding="same"),
        LeakyReLU(alpha=0.2),
        Conv2D(3, (3, 3), activation="tanh", padding="same"),
    ])
    return model

# Build Discriminator
def build_discriminator():
    model = Sequential([
        Conv2D(64, (3, 3), strides=(2, 2), input_shape=(128, 128, 3), padding="same"),
        LeakyReLU(alpha=0.2),
        Conv2D(128, (3, 3), strides=(2, 2), padding="same"),
        LeakyReLU(alpha=0.2),
        Flatten(),
        Dense(1, activation="sigmoid"),
    ])
    return model

# Compile GAN
discriminator = build_discriminator()
discriminator.compile(optimizer=Adam(0.0002, 0.5), loss="binary_crossentropy", metrics=["accuracy"])

generator = build_generator()
gan = Sequential([generator, discriminator])
gan.compile(optimizer=Adam(0.0002, 0.5), loss="binary_crossentropy")

# Train GAN
# Use similar training loop as before

# 4. Predict on Test Data

# Load the test data
def load_test_data(test_dir, img_size):
    test_images = []
    test_ids = []
    for img_name in os.listdir(test_dir):
        img_path = os.path.join(test_dir, img_name)
        img = load_img(img_path, target_size=img_size)
        img_array = img_to_array(img) / 255.0
        test_images.append(img_array)
        test_ids.append(img_name)
    return np.array(test_images), test_ids

test_images, test_ids = load_test_data(test_dir, img_size)

# Predict probabilities using the CNN model
cnn_model = tf.keras.models.load_model("cnn_real_vs_ai.h5")
predictions = cnn_model.predict(test_images)
probabilities = predictions.flatten()

# Generate submission file
submission = pd.DataFrame({
    "Id": test_ids,
    "Label": ["AI" if prob > 0.5 else "Real" for prob in probabilities]
})
submission.to_csv(output_csv, index=False)
print(f"Submission saved to {output_csv}")
