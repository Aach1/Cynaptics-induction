# This was used in Gradient competition on kaggle

# 1. Preprocessing and Dataset Loading

import os
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_auc_score

# Paths
train_dir = "path/to/dataset/train"
test_dir = "path/to/dataset/test"
output_csv = "submission.csv"

# Image size and batch size
img_size = (128, 128)
batch_size = 32

# Load training data
train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="training",
)
val_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="validation",
)

# 2. Train a CNN Classifier

# Build the CNN model
cnn_model = Sequential([
    Conv2D(32, (3, 3), activation="relu", input_shape=(128, 128, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation="relu"),
    Dropout(0.5),
    Dense(1, activation="sigmoid"),  # Binary classification
])

cnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Train the CNN model
early_stop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
cnn_model.fit(train_data, validation_data=val_data, epochs=20, callbacks=[early_stop])

# Save the trained model
cnn_model.save("cnn_real_vs_ai.h5")
